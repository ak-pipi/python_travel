# -*- encoding:utf-8 -*-
"""
    @project: Langchain_agent
    @Authorï¼špiyj
    @fileï¼š summary_generator.py
    @timeï¼š2025/8/26 13:28
"""

from typing import Dict, Any, Optional
from utils.deepseek_client import deepseek_client
from utils.summary_templates import get_summary_prompt
import re


class SummaryGenerator:
    def __init__(self):
        self.min_length = 500  # æœ€å°å­—æ•°
        self.max_length = 800  # æœ€å¤§å­—æ•°

    def generate_travel_summary(self, user_input: str, answers: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆæ—…è¡Œéœ€æ±‚æ€»ç»“

        Args:
            user_input: ç”¨æˆ·åˆå§‹éœ€æ±‚
            answers: ç”¨æˆ·çš„é—®é¢˜ç­”æ¡ˆ

        Returns:
            åŒ…å«æ€»ç»“å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        try:
            # éªŒè¯è¾“å…¥
            if not answers:
                return self._get_error_response("æœªæä¾›ç­”æ¡ˆæ•°æ®")

            # ç”Ÿæˆæç¤ºè¯
            prompt = get_summary_prompt(user_input, answers)

            # è°ƒç”¨AIç”Ÿæˆæ€»ç»“
            print("ğŸ”„ æ­£åœ¨ç”Ÿæˆæ—…è¡Œéœ€æ±‚æ€»ç»“...")
            response = deepseek_client.llm.invoke(prompt)
            summary_text = response.content.strip()

            # æ¸…ç†å’ŒéªŒè¯æ€»ç»“å†…å®¹
            cleaned_summary = self._clean_summary(summary_text)

            # æ£€æŸ¥å­—æ•°
            word_count = self._count_words(cleaned_summary)
            if word_count > self.max_length:
                cleaned_summary = self._truncate_summary(cleaned_summary)
                word_count = self._count_words(cleaned_summary)

            # æå–å…³é”®ä¿¡æ¯
            key_points = self._extract_key_points(cleaned_summary)

            return {
                "status": "success",
                "summary": cleaned_summary,
                "word_count": word_count,
                "key_points": key_points,
                "is_truncated": word_count >= self.max_length
            }

        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ€»ç»“æ—¶å‡ºé”™: {e}")
            return self._get_error_response(f"ç”Ÿæˆæ€»ç»“æ—¶å‡ºé”™: {str(e)}")


    def _clean_summary(self, text: str) -> str:
        """æ¸…ç†æ€»ç»“æ–‡æœ¬"""
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text).strip()

        # ç§»é™¤å¯èƒ½å­˜åœ¨çš„markdownæ ‡è®°
        text = re.sub(r'[*#_\-]', '', text)

        # ç¡®ä¿ä»¥å¥å·ç»“æŸ
        if not text.endswith(('.', 'ã€‚', '!', 'ï¼', '?', 'ï¼Ÿ')):
            text += 'ã€‚'

        return text

    def _count_words(self, text: str) -> int:
        """è®¡ç®—ä¸­æ–‡å­—æ•°"""
        # ä¸­æ–‡å•è¯è®¡æ•°ï¼ˆå¤§è‡´ï¼‰
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        # éä¸­æ–‡éƒ¨åˆ†æŒ‰ç©ºæ ¼åˆ†å‰²
        other_parts = len(re.findall(r'\S+', re.sub(r'[\u4e00-\u9fff]', '', text)))
        return chinese_chars + other_parts

    def _truncate_summary(self, text: str) -> str:
        """æˆªæ–­è¶…è¿‡å­—æ•°é™åˆ¶çš„æ€»ç»“"""
        words = []
        current_count = 0

        # ç®€å•çš„æŒ‰å¥å­æˆªæ–­
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', text)

        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue

            sentence_word_count = self._count_words(sentence)
            if current_count + sentence_word_count <= self.max_length:
                words.append(sentence)
                current_count += sentence_word_count
            else:
                break

        # é‡æ–°ç»„åˆå¹¶ç¡®ä¿å®Œæ•´æ€§
        truncated_text = 'ã€‚'.join(words) + 'ã€‚'
        if self._count_words(truncated_text) < self.min_length:
            # å¦‚æœå¤ªçŸ­ï¼Œè¿”å›åŸå§‹æ–‡æœ¬çš„å‰800å­—
            truncated_text = text[:800] + '...'

        return truncated_text

    def _extract_key_points(self, summary: str) -> Dict[str, str]:
        """ä»æ€»ç»“ä¸­æå–å…³é”®ä¿¡æ¯ç‚¹"""
        key_points = {
            "budget": "æœªæåŠ",
            "duration": "æœªæåŠ",
            "theme": "æœªæåŠ",
            "destination": "æœªæåŠ"
        }

        # ç®€å•çš„å…³é”®è¯æå–
        budget_keywords = ['é¢„ç®—', 'ä»·æ ¼', 'è´¹ç”¨', 'èŠ±è´¹', 'å…ƒ', 'é’±']
        duration_keywords = ['å¤©', 'æ—¶é—´', 'è¡Œç¨‹', 'å‘¨æœŸ', 'å®‰æ’']
        theme_keywords = ['ä¸»é¢˜', 'ç±»å‹', 'é£æ ¼', 'ä½“éªŒ', 'ç›®çš„']
        destination_keywords = ['åœ°æ–¹', 'ç›®çš„åœ°', 'åŸå¸‚', 'å›½å®¶', 'åœ°åŒº', 'æ™¯ç‚¹']

        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', summary)

        for sentence in sentences:
            sentence = sentence.strip()
            if any(keyword in sentence for keyword in budget_keywords):
                key_points["budget"] = sentence
            elif any(keyword in sentence for keyword in duration_keywords):
                key_points["duration"] = sentence
            elif any(keyword in sentence for keyword in theme_keywords):
                key_points["theme"] = sentence
            elif any(keyword in sentence for keyword in destination_keywords):
                key_points["destination"] = sentence

        return key_points

    def _get_error_response(self, message: str) -> Dict[str, Any]:
        """è·å–é”™è¯¯å“åº”"""
        return {
            "status": "error",
            "summary": "",
            "message": message,
            "word_count": 0,
            "key_points": {},
            "is_truncated": False
        }


# åˆ›å»ºå•ä¾‹å®ä¾‹
summary_generator = SummaryGenerator()